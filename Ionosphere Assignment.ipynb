{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Ionosphere Data Problem\n",
    "\n",
    "### Dataset Description: \n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW :\n",
    "- Load Data\n",
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column.\n",
    "- Shuffle the data if needed.\n",
    "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
    "- Split into 60 and 40 ratio.\n",
    "- Encode labels.\n",
    "- Model : 1 hidden layers including 16 unit.\n",
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "- Train the Model with Epochs (100).\n",
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**\n",
    "- Evaluation Step\n",
    "- Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0           1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1           1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2           1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3           1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4           1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "346         1         0   0.83508   0.08298   0.73739  -0.14706   0.84349   \n",
       "347         1         0   0.95113   0.00419   0.95183  -0.02723   0.93438   \n",
       "348         1         0   0.94701  -0.00034   0.93207  -0.03227   0.95177   \n",
       "349         1         0   0.90608  -0.01657   0.98122  -0.01989   0.95691   \n",
       "350         1         0   0.84710   0.13533   0.73638  -0.06151   0.87873   \n",
       "\n",
       "     feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0    -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1    -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2    -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3    -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4    -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "..        ...       ...        ...  ...        ...        ...        ...   \n",
       "346  -0.05567   0.90441   -0.04622  ...   -0.04202    0.83479    0.00123   \n",
       "347  -0.01920   0.94590    0.01606  ...    0.01361    0.93522    0.04925   \n",
       "348  -0.03431   0.95584    0.02446  ...    0.03193    0.92489    0.02542   \n",
       "349  -0.03646   0.85746    0.00110  ...   -0.02099    0.89147   -0.07760   \n",
       "350   0.08260   0.88928   -0.09139  ...   -0.15114    0.81147   -0.04822   \n",
       "\n",
       "     feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0      0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1     -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2      0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3      1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4      0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "..         ...        ...        ...        ...        ...        ...    ...  \n",
       "346    1.00000    0.12815    0.86660   -0.10714    0.90546   -0.04307      g  \n",
       "347    0.93159    0.08168    0.94066   -0.00035    0.91483    0.04712      g  \n",
       "348    0.92120    0.02242    0.92459    0.00442    0.92697   -0.00577      g  \n",
       "349    0.82983   -0.17238    0.96022   -0.03757    0.87403   -0.16243      g  \n",
       "350    0.78207   -0.00703    0.75747   -0.06678    0.85764   -0.06151      g  \n",
       "\n",
       "[351 rows x 35 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"archive/ionosphere_data.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.0</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1  feature2    feature3    feature4    feature5    feature6  \\\n",
       "count  351.000000     351.0  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738       0.0    0.641342    0.044372    0.601068    0.115889   \n",
       "std      0.311155       0.0    0.497708    0.441435    0.519862    0.460810   \n",
       "min      0.000000       0.0   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000       0.0    0.472135   -0.064735    0.412660   -0.024795   \n",
       "50%      1.000000       0.0    0.871110    0.016310    0.809200    0.022800   \n",
       "75%      1.000000       0.0    1.000000    0.194185    1.000000    0.334655   \n",
       "max      1.000000       0.0    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature7    feature8    feature9   feature10  ...   feature25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.550095    0.119360    0.511848    0.181345  ...    0.396135   \n",
       "std      0.492654    0.520750    0.507066    0.483851  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%      0.211310   -0.054840    0.087110   -0.048075  ...    0.000000   \n",
       "50%      0.728730    0.014710    0.684210    0.018290  ...    0.553890   \n",
       "75%      0.969240    0.445675    0.953240    0.534195  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature2     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature2     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, X_test = train_test_split(dataset, train_size = 0.6, test_size = 0.4, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90071</td>\n",
       "      <td>0.01773</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.01773</td>\n",
       "      <td>0.90071</td>\n",
       "      <td>0.00709</td>\n",
       "      <td>0.84752</td>\n",
       "      <td>0.05674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90071</td>\n",
       "      <td>0.04610</td>\n",
       "      <td>0.94305</td>\n",
       "      <td>0.03247</td>\n",
       "      <td>0.94681</td>\n",
       "      <td>0.02482</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.01064</td>\n",
       "      <td>0.93617</td>\n",
       "      <td>0.02128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.37838</td>\n",
       "      <td>0.64865</td>\n",
       "      <td>0.29730</td>\n",
       "      <td>0.64865</td>\n",
       "      <td>-0.24324</td>\n",
       "      <td>0.86486</td>\n",
       "      <td>0.18919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35135</td>\n",
       "      <td>-0.29730</td>\n",
       "      <td>0.61031</td>\n",
       "      <td>-0.22163</td>\n",
       "      <td>0.58478</td>\n",
       "      <td>-0.23027</td>\n",
       "      <td>0.72973</td>\n",
       "      <td>-0.59459</td>\n",
       "      <td>0.51351</td>\n",
       "      <td>-0.24324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85013</td>\n",
       "      <td>0.01809</td>\n",
       "      <td>0.92211</td>\n",
       "      <td>0.01456</td>\n",
       "      <td>0.92046</td>\n",
       "      <td>0.02180</td>\n",
       "      <td>0.92765</td>\n",
       "      <td>0.08010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83721</td>\n",
       "      <td>0.10853</td>\n",
       "      <td>0.86923</td>\n",
       "      <td>0.08950</td>\n",
       "      <td>0.87597</td>\n",
       "      <td>0.08786</td>\n",
       "      <td>0.85198</td>\n",
       "      <td>0.10134</td>\n",
       "      <td>0.84258</td>\n",
       "      <td>0.10698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.58459</td>\n",
       "      <td>-0.35526</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.35338</td>\n",
       "      <td>0.75376</td>\n",
       "      <td>-0.00564</td>\n",
       "      <td>0.82519</td>\n",
       "      <td>0.19361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64850</td>\n",
       "      <td>-0.04699</td>\n",
       "      <td>0.56836</td>\n",
       "      <td>-0.10571</td>\n",
       "      <td>0.52820</td>\n",
       "      <td>-0.13346</td>\n",
       "      <td>0.15602</td>\n",
       "      <td>-0.12218</td>\n",
       "      <td>0.44767</td>\n",
       "      <td>-0.10309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35346</td>\n",
       "      <td>-0.13768</td>\n",
       "      <td>0.69387</td>\n",
       "      <td>-0.02423</td>\n",
       "      <td>0.68195</td>\n",
       "      <td>-0.03574</td>\n",
       "      <td>0.55717</td>\n",
       "      <td>-0.06119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45008</td>\n",
       "      <td>-0.00564</td>\n",
       "      <td>0.39146</td>\n",
       "      <td>-0.09038</td>\n",
       "      <td>0.35588</td>\n",
       "      <td>-0.10306</td>\n",
       "      <td>0.32232</td>\n",
       "      <td>-0.08637</td>\n",
       "      <td>0.28943</td>\n",
       "      <td>-0.08300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39394</td>\n",
       "      <td>-0.24242</td>\n",
       "      <td>0.62655</td>\n",
       "      <td>0.01270</td>\n",
       "      <td>0.45455</td>\n",
       "      <td>0.09091</td>\n",
       "      <td>0.63636</td>\n",
       "      <td>0.09091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48526</td>\n",
       "      <td>0.05929</td>\n",
       "      <td>0.46362</td>\n",
       "      <td>0.06142</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>-0.03030</td>\n",
       "      <td>0.41856</td>\n",
       "      <td>0.06410</td>\n",
       "      <td>0.39394</td>\n",
       "      <td>0.24242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99701</td>\n",
       "      <td>0.21677</td>\n",
       "      <td>0.91966</td>\n",
       "      <td>0.47030</td>\n",
       "      <td>0.76902</td>\n",
       "      <td>0.62415</td>\n",
       "      <td>0.53312</td>\n",
       "      <td>0.78120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.64658</td>\n",
       "      <td>0.15908</td>\n",
       "      <td>-0.66651</td>\n",
       "      <td>0.02277</td>\n",
       "      <td>-0.64872</td>\n",
       "      <td>-0.13462</td>\n",
       "      <td>-0.54615</td>\n",
       "      <td>-0.22949</td>\n",
       "      <td>-0.47201</td>\n",
       "      <td>-0.35032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96355</td>\n",
       "      <td>-0.07198</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14333</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.21313</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.36174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85106</td>\n",
       "      <td>-0.65440</td>\n",
       "      <td>0.57577</td>\n",
       "      <td>-0.69712</td>\n",
       "      <td>0.25435</td>\n",
       "      <td>-0.63919</td>\n",
       "      <td>0.45114</td>\n",
       "      <td>-0.72779</td>\n",
       "      <td>0.38895</td>\n",
       "      <td>-0.73420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "29          0         0  -1.00000  -1.00000   1.00000   1.00000   1.00000   \n",
       "322         1         0   0.90071   0.01773   1.00000  -0.01773   0.90071   \n",
       "139         1         0   1.00000  -0.37838   0.64865   0.29730   0.64865   \n",
       "319         1         0   0.85013   0.01809   0.92211   0.01456   0.92046   \n",
       "285         1         0   0.58459  -0.35526   1.00000   0.35338   0.75376   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "79          0         0   1.00000   1.00000   1.00000  -1.00000   1.00000   \n",
       "343         1         0   0.35346  -0.13768   0.69387  -0.02423   0.68195   \n",
       "323         1         0   0.39394  -0.24242   0.62655   0.01270   0.45455   \n",
       "280         1         0   0.99701   0.21677   0.91966   0.47030   0.76902   \n",
       "8           1         0   0.96355  -0.07198   1.00000  -0.14333   1.00000   \n",
       "\n",
       "     feature8  feature9  feature10  ...  feature25  feature26  feature27  \\\n",
       "29   -1.00000  -1.00000    1.00000  ...    1.00000    1.00000    1.00000   \n",
       "322   0.00709   0.84752    0.05674  ...    0.90071    0.04610    0.94305   \n",
       "139  -0.24324   0.86486    0.18919  ...    0.35135   -0.29730    0.61031   \n",
       "319   0.02180   0.92765    0.08010  ...    0.83721    0.10853    0.86923   \n",
       "285  -0.00564   0.82519    0.19361  ...    0.64850   -0.04699    0.56836   \n",
       "..        ...       ...        ...  ...        ...        ...        ...   \n",
       "79    1.00000  -1.00000    1.00000  ...    1.00000   -1.00000    1.00000   \n",
       "343  -0.03574   0.55717   -0.06119  ...    0.45008   -0.00564    0.39146   \n",
       "323   0.09091   0.63636    0.09091  ...    0.48526    0.05929    0.46362   \n",
       "280   0.62415   0.53312    0.78120  ...   -0.64658    0.15908   -0.66651   \n",
       "8    -0.21313   1.00000   -0.36174  ...    0.85106   -0.65440    0.57577   \n",
       "\n",
       "     feature28  feature29  feature30  feature31  feature32  feature33  \\\n",
       "29    -1.00000    1.00000   -1.00000   -1.00000    1.00000    1.00000   \n",
       "322    0.03247    0.94681    0.02482    1.00000    0.01064    0.93617   \n",
       "139   -0.22163    0.58478   -0.23027    0.72973   -0.59459    0.51351   \n",
       "319    0.08950    0.87597    0.08786    0.85198    0.10134    0.84258   \n",
       "285   -0.10571    0.52820   -0.13346    0.15602   -0.12218    0.44767   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "79     1.00000    1.00000    1.00000    1.00000   -1.00000   -1.00000   \n",
       "343   -0.09038    0.35588   -0.10306    0.32232   -0.08637    0.28943   \n",
       "323    0.06142    0.33333   -0.03030    0.41856    0.06410    0.39394   \n",
       "280    0.02277   -0.64872   -0.13462   -0.54615   -0.22949   -0.47201   \n",
       "8     -0.69712    0.25435   -0.63919    0.45114   -0.72779    0.38895   \n",
       "\n",
       "     feature34  \n",
       "29    -1.00000  \n",
       "322    0.02128  \n",
       "139   -0.24324  \n",
       "319    0.10698  \n",
       "285   -0.10309  \n",
       "..         ...  \n",
       "79     1.00000  \n",
       "343   -0.08300  \n",
       "323    0.24242  \n",
       "280   -0.35032  \n",
       "8     -0.73420  \n",
       "\n",
       "[210 rows x 34 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salemo/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "Y_train = X_train['label']\n",
    "# now droping the price column from the input dataset\n",
    "X_train.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = X_test['label']\n",
    "# now droping the price column from the input dataset\n",
    "X_test.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization (encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the label column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "Y_train = label_encoder.fit_transform(Y_train)\n",
    "Y_test = label_encoder.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model = Sequential() # Initialising the ANN\n",
    "\n",
    "model.add(Dense(units = 32, activation = 'relu', kernel_regularizer=regularizers.l2(0.01), input_shape = (X_train.shape[1],)))\n",
    "model.add(Dense(units = 16, activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.2393 - accuracy: 0.5244\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.1105 - accuracy: 0.6593\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0177 - accuracy: 0.7854\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0163 - accuracy: 0.7424\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9168 - accuracy: 0.7949\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9051 - accuracy: 0.7863\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8703 - accuracy: 0.8351\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8187 - accuracy: 0.8491\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.7836 - accuracy: 0.8543\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.7647 - accuracy: 0.8685\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.8521\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7373 - accuracy: 0.8769\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.9047\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.8920\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.9125\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5938 - accuracy: 0.9117\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.9257\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.9453\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.9227\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.9467\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.9456\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.9323\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.9427\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.9570\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.9410\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.9634\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.9530\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.9613\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.9363\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4017 - accuracy: 0.9553\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.9737\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.9723\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.9642\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.9740\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.9717\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.9508\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.9707\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.9704\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.9612\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.9810\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.9795\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.9739\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.9771\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.9728\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.9908\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.9739\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.9649\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.9827\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.9649\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.9692\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.9708\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.9719\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.9666\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.9811\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2606 - accuracy: 0.9763\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.9763\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.9786\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.9711\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.9643\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.9685\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.9596\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.9848\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.9792\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9853\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.9720\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9762\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9782\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9776\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.9605\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2357 - accuracy: 0.9685\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9667\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9752\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.9744\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9772\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2410 - accuracy: 0.9682\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9709\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9729\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9628\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9800\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9699\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9864\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.9793\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.9768\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9778\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.9833\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.9748\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9744\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9737\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9824\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9812\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9616\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9786\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9795\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9846\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.9673\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2103 - accuracy: 0.9579\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9729\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9705\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9780\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ec80e4790>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the data\n",
    "model.fit(X_train, Y_train, batch_size = 20, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8706818e-01],\n",
       "       [7.1803778e-01],\n",
       "       [2.6926559e-01],\n",
       "       [9.8643100e-01],\n",
       "       [9.6586049e-03],\n",
       "       [7.1594536e-02],\n",
       "       [8.4948063e-01],\n",
       "       [1.2852037e-01],\n",
       "       [9.8299313e-01],\n",
       "       [3.0397856e-01],\n",
       "       [6.0126400e-01],\n",
       "       [9.6769881e-01],\n",
       "       [9.3551195e-01],\n",
       "       [5.7564318e-02],\n",
       "       [9.6115357e-01],\n",
       "       [9.8935544e-01],\n",
       "       [9.9427235e-01],\n",
       "       [9.6865523e-01],\n",
       "       [8.4715068e-01],\n",
       "       [8.5442930e-02],\n",
       "       [9.6787000e-01],\n",
       "       [9.8192835e-01],\n",
       "       [8.1695342e-01],\n",
       "       [9.7169423e-01],\n",
       "       [9.8597443e-01],\n",
       "       [9.8631936e-01],\n",
       "       [1.5183538e-02],\n",
       "       [8.1089473e-01],\n",
       "       [9.2317933e-01],\n",
       "       [9.9561757e-01],\n",
       "       [9.8525667e-01],\n",
       "       [9.8958027e-01],\n",
       "       [9.7392398e-01],\n",
       "       [8.3368897e-02],\n",
       "       [9.8995000e-01],\n",
       "       [9.9080485e-01],\n",
       "       [2.1029174e-01],\n",
       "       [9.8145700e-01],\n",
       "       [2.1043181e-02],\n",
       "       [8.3753902e-01],\n",
       "       [4.8044324e-04],\n",
       "       [9.8116553e-01],\n",
       "       [5.0356150e-02],\n",
       "       [9.8964965e-01],\n",
       "       [9.8844731e-01],\n",
       "       [9.9338937e-01],\n",
       "       [9.6242285e-01],\n",
       "       [9.0818167e-01],\n",
       "       [9.8309338e-01],\n",
       "       [7.6917732e-01],\n",
       "       [9.9044317e-01],\n",
       "       [8.6266708e-01],\n",
       "       [8.3954304e-01],\n",
       "       [9.9221665e-01],\n",
       "       [1.5401825e-01],\n",
       "       [9.9141741e-01],\n",
       "       [1.1672378e-03],\n",
       "       [8.8000840e-01],\n",
       "       [1.2521058e-02],\n",
       "       [9.4079149e-01],\n",
       "       [9.7216928e-01],\n",
       "       [9.9171484e-01],\n",
       "       [9.6115166e-01],\n",
       "       [9.8682684e-01],\n",
       "       [9.6658093e-01],\n",
       "       [1.4220953e-02],\n",
       "       [1.8050569e-01],\n",
       "       [9.0725076e-01],\n",
       "       [1.2939483e-02],\n",
       "       [2.0399302e-02],\n",
       "       [9.9270058e-01],\n",
       "       [6.0294169e-01],\n",
       "       [6.5873861e-03],\n",
       "       [1.4983594e-02],\n",
       "       [5.5356771e-01],\n",
       "       [9.8447031e-01],\n",
       "       [1.9766605e-01],\n",
       "       [9.6036410e-01],\n",
       "       [8.9923048e-01],\n",
       "       [9.9115866e-01],\n",
       "       [2.2013783e-03],\n",
       "       [9.9226475e-01],\n",
       "       [9.8820662e-01],\n",
       "       [9.8431242e-01],\n",
       "       [6.4846337e-01],\n",
       "       [9.9290663e-01],\n",
       "       [9.7158992e-01],\n",
       "       [8.9297682e-01],\n",
       "       [9.7502005e-01],\n",
       "       [9.9611533e-01],\n",
       "       [1.6672599e-01],\n",
       "       [3.2738501e-01],\n",
       "       [9.4537830e-01],\n",
       "       [9.8241192e-01],\n",
       "       [9.7103727e-01],\n",
       "       [5.1467985e-02],\n",
       "       [9.8763645e-01],\n",
       "       [9.2880565e-01],\n",
       "       [7.8185087e-01],\n",
       "       [9.8641586e-01],\n",
       "       [9.9515390e-01],\n",
       "       [9.3795252e-01],\n",
       "       [7.3400629e-01],\n",
       "       [1.0731220e-03],\n",
       "       [9.6350777e-01],\n",
       "       [1.3507962e-02],\n",
       "       [2.7279225e-01],\n",
       "       [9.8943257e-01],\n",
       "       [3.5846561e-02],\n",
       "       [2.6324093e-02],\n",
       "       [9.7336406e-01],\n",
       "       [9.8743546e-01],\n",
       "       [5.0264496e-01],\n",
       "       [1.7331839e-03],\n",
       "       [1.5866652e-01],\n",
       "       [1.1385402e-01],\n",
       "       [9.9250042e-01],\n",
       "       [9.8973715e-01],\n",
       "       [9.8718160e-01],\n",
       "       [9.7132421e-01],\n",
       "       [9.5745331e-01],\n",
       "       [1.1757463e-02],\n",
       "       [9.8999411e-01],\n",
       "       [9.7568524e-01],\n",
       "       [9.7972655e-01],\n",
       "       [8.0431581e-01],\n",
       "       [9.8783773e-01],\n",
       "       [8.9077991e-01],\n",
       "       [9.9251246e-01],\n",
       "       [4.8983395e-03],\n",
       "       [2.0400286e-03],\n",
       "       [2.8749412e-01],\n",
       "       [9.8023504e-01],\n",
       "       [8.4875882e-01],\n",
       "       [9.9256957e-01],\n",
       "       [9.6203697e-01],\n",
       "       [9.0636992e-01],\n",
       "       [9.9522984e-01],\n",
       "       [3.6105633e-02],\n",
       "       [9.8280573e-01],\n",
       "       [9.8496079e-01]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting data from X_test\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4450204372406006, 0.8794326186180115]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
